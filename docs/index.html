<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<title>ARC Imagination Engine — How It Works</title>
	<link rel="stylesheet" href="./globals.css" />
</head>
<body>
	<header class="site-header">
		<div class="container brand">
			<div class="title">ARC Imagination Engine</div>
			<div class="tag">Canvas + Planner + Readout</div>
			<div class="tag">Self-play probes</div>
			<div class="tag">In-episode adaptation</div>
		</div>
	</header>

	<main class="container">
		<section>
			<h1>What is this?</h1>
			<p>
				This document explains the system we are building to solve ARC tasks. Predictions are JSON grids (list of lists of 0–9). We keep a persistent 32×32 latent <span class="badge accent">Canvas</span> (Sim2D), apply localized <span class="badge">Brush Edits</span>, and decode to grids via a <span class="badge">Readout</span>. A <span class="badge">Planner</span> (MLP or LLM) proposes edits; a closed-loop search picks what works best on the task's train pairs before answering the test input.
			</p>
			<div class="diagram">
				<div class="block col-3">Input Grid(s)</div>
				<div class="arrow col-1">→</div>
				<div class="block col-3">Readout Summary<br/>+ Episodic Memory</div>
				<div class="arrow col-1">→</div>
				<div class="block col-4">Planner (MLP or LLM)<br/>probes + programs</div>
				<div class="arrow col-12">↓</div>
				<div class="block col-12">Canvas (32×32×C) ⇄ Sim2D dynamics + Brush Edits</div>
				<div class="arrow col-12">↓</div>
				<div class="block col-6">Argmax over channels 0–9</div>
				<div class="arrow col-1">→</div>
				<div class="block col-5">Predicted Grid (JSON)</div>
			</div>
			<p class="callout">ARC grids are ≤30×30; our 32×32 Canvas safely covers that. We decode by taking argmax across the 10 color channels.</p>
		</section>

		<section>
			<h2>Key components</h2>
			<div class="grid">
				<div class="card col-6">
					<h3>Canvas (Sim2D)</h3>
					<p>A persistent latent board of size 32×32×C updated by a tiny transformer. Channels 0–9 represent color logits; the remaining channels act as working memory, including optional <em>rule slots</em> for episodic knowledge.</p>
					<ul class="clean">
						<li><span class="badge">C ≥ 32</span> with <span class="badge">8–16 episodic</span> channels for rule vectors.</li>
						<li>Update is differentiable: S ← S + mask × (scale × delta).</li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Brush Edit</h3>
					<p>One localized, soft update parameterized by <code class="inline">[x, y, radius, scale, delta_vector[C]]</code>. K edits are applied per step.</p>
					<ul class="clean">
						<li><span class="badge">K (edits/step): 3</span></li>
						<li><span class="badge">Steps/attempt: 8–16</span></li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Planner</h3>
					<p>Chooses which edits to apply. Start with a tiny MLP; upgrade to a 7B LLM (Qwen2.5 or DeepSeek-R1-Distill-Qwen) that emits edit tokens, not text.</p>
					<ul class="clean">
						<li><span class="badge">planner: mlp | llm</span></li>
						<li><span class="badge">in_episode_adapt</span> (LoRA steps 1–5)</li>
						<li><span class="badge">search_over_edits</span> (R candidates)</li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Readout</h3>
					<p>Summarizes the Canvas for the planner, and decodes the final Canvas into a grid (argmax on channels 0–9). Keeps the LLM grounded by providing compact, structured state.</p>
				</div>
			</div>
		</section>

		<section>
			<h2>Learning on the fly (per task episode)</h2>
			<p>ARC provides train pairs inside each task. We run <strong>self‑play probes</strong> (try→observe→update) so the system discovers the explanation before predicting the test grid.</p>
			<ul class="checklist">
				<li><span class="dot"></span> Probes: toggle holes, flip axis, undo‑shift, shift by period; observe outcomes.</li>
				<li><span class="dot"></span> Belief update over hypotheses + slots; 1–5 tiny adaptation steps; reset after episode.</li>
				<li><span class="dot"></span> Score = Fit + (1−Why) + Stability + Simplicity; apply the winning program to the test input.</li>
			</ul>
			<table class="table">
				<tr><th>Knob</th><th>Recommended</th><th>Effect</th></tr>
				<tr><td>adapt_steps</td><td>2</td><td>Faster inner loop, avoids overfitting</td></tr>
				<tr><td>adapt_lr</td><td>1e-3 → 5e-4</td><td>Stability of LoRA updates</td></tr>
				<tr><td>R (candidates)</td><td>8–32</td><td>Search breadth for hypotheses</td></tr>
				<tr><td>attempts</td><td>3 (ARC‑AGI‑1), 2 (ARC‑AGI‑2)</td><td>Multiple independent stories per test input</td></tr>
			</table>
			<p class="callout">Weights reset after each episode so nothing leaks across tasks. Outer training still improves base models over time.</p>
		</section>

		<section>
			<h2>Why self‑play imagination + reasoning?</h2>
			<p>
				Imagination gives a spatial scratchpad and controllable local edits. Reasoning (planner) proposes probes/programs. Self‑play probes + belief updates prefer explanations that fit all train pairs and pass “why” checks.
			</p>
			<div class="grid">
				<div class="card col-6 kpi"><div class="value">Local</div><div class="label">geometric changes, copying, symmetry</div></div>
				<div class="card col-6 kpi"><div class="value">Global</div><div class="label">counting, parity, set/logical rules</div></div>
			</div>
		</section>

		<section>
			<h2>Stages</h2>
			<div class="grid">
				<div class="card col-6">
					<h3>Stage 0 — Canvas grounding</h3>
					<ul class="clean">
						<li><strong>Train</strong>: small conv Sim2D (state update) + decode head</li>
						<li><strong>Objectives</strong>: recon_ce (grid CE), next_step_mse (under random edits), cycle_ce (mirror×2/rotate×4), leakage</li>
						<li><strong>Data</strong>: ARC train inputs/outputs pooled as unlabeled states + flip/rot90 aug</li>
						<li><strong>Outputs</strong>: canvas_stage0.safetensors, metrics.jsonl, samples/*.png</li>
						<li><strong>Done when</strong>: recon_ce ↓≥50% & <0.8; next_step_mse ↓≥30%; cycle_ce <0.05; max_logit >0.75</li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Stage 1 — Slots & motifs</h3>
					<ul class="clean">
						<li><strong>Train</strong>: slot/event heads (event, axis, dy/dx, feature); optional VQ motif codes</li>
						<li><strong>Objectives</strong>: CE for slot heads + Stage 0 losses to keep Canvas stable</li>
						<li><strong>Data</strong>: synthetic episodes (recolor-by-feature, mirror/rotate/translate, stripes/tiling, relations)</li>
						<li><strong>Outputs</strong>: readout_stage1.safetensors (+ sim2d_stage1 if unfrozen), metrics_stage1.jsonl</li>
						<li><strong>Done when</strong>: event_type_acc ≥0.80; axis_acc ≥0.90; translate_acc ≥0.70; Stage 0 gates still green</li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Stage 2 — Self‑play explanation</h3>
					<ul class="clean">
						<li><strong>Train/Aim</strong>: episode loop that runs probes (try→observe→update), maintains belief over programs + slots</li>
						<li><strong>How</strong>: probe policy (toggle hole / axis flip / undo‑shift / period shift), simulate on Canvas, update belief/slots</li>
						<li><strong>Score</strong>: Fit (avg train loss) + (1−Why) (probe pass) + Stability (slot variance) + Simplicity (MDL)</li>
						<li><strong>Outputs</strong>: episode_report.json (chosen program, slots, probe pass/fail), test JSON grids</li>
						<li><strong>Done when</strong>: consistent episode reports; higher exact‑match on a dev slice vs. baselines</li>
					</ul>
				</div>
				<div class="card col-6">
					<h3>Stage 3 — LLM planner (optional)</h3>
					<ul class="clean">
						<li><strong>Train</strong>: LoRA‑tune 7B (Qwen/DeepSeek) to emit probes/programs from readout</li>
						<li><strong>Objectives</strong>: Stage 2 score as supervision (fit + why + stability + simplicity)</li>
						<li><strong>Data</strong>: ARC episodes; synthetic for warm‑starts</li>
						<li><strong>Outputs</strong>: LoRA adapters (+ merged), improved episode reports and dev accuracy</li>
					</ul>
				</div>
			</div>
		</section>

		<section>
			<h2>How to run</h2>
			<p>Windows cmd, using the repo root as working dir:</p>
			<pre><code>python -m venv .venv
.\.venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt

python run_loop.py --config configs\arc_mvp.yaml
python src\train_boot.py --config configs\arc_mvp.yaml

set ARC_TRAIN_DIR=C:\Users\oy\Documents\arc_imagination_project\ARC-AGI\data\training
python src\train_arc.py --config configs\arc_mvp.yaml

python src\eval_arc.py --config configs\arc_mvp.yaml --task_dir C:\Users\oy\Documents\arc_imagination_project\ARC-AGI\data\evaluation --out_dir submissions\arc1_model

set ARC_TRAIN_DIR=C:\Users\oy\Documents\arc_imagination_project\ARC-AGI-2\data\training
python src\train_arc.py --config configs\arc_mvp.yaml
python src\eval_arc.py --config configs\arc_mvp.yaml --task_dir C:\Users\oy\Documents\arc_imagination_project\ARC-AGI-2\data\evaluation --out_dir submissions\arc2_model</code></pre>
			<p class="muted">Outputs are per-task JSON grids compatible with the official scorer.</p>
		</section>

		<section>
			<h2>Switching baselines</h2>
			<ul class="checklist">
				<li><span class="dot"></span><strong>A</strong>: <code class="inline">use_edits=false</code> (no imagination)</li>
				<li><span class="dot"></span><strong>B</strong>: <code class="inline">use_edits=true</code>, <code class="inline">planner=mlp</code>, <code class="inline">search_over_edits=true</code></li>
				<li><span class="dot"></span><strong>C</strong>: <code class="inline">planner=llm</code> (Qwen2.5‑7B or DeepSeek-R1‑Distill‑Qwen‑7B, 4‑bit + LoRA + MERGE)</li>
			</ul>
		</section>

		<section>
			<h2>FAQ</h2>
			<p><strong>Q: Do we need text outputs?</strong> No. The LLM emits edit tokens. Final outputs are grids.</p>
			<p><strong>Q: Why 32×32?</strong> ARC ≤30×30. 32×32 is a safe power-of-two canvas.</p>
			<p><strong>Q: Can it learn a task’s rule on the fly?</strong> Yes—via LoRA inner-loop updates and/or episodic memory channels, plus search-over-edits.</p>
		</section>

		<p class="footer-note">This document summarizes <em>20250819_changelog.md</em> and <em>PROJECT_PLAN.md</em> in an implementation-oriented view.</p>
	</main>
</body>
</html>


